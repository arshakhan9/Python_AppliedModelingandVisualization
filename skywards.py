# -*- coding: utf-8 -*-
"""MAV_Summative_BP0274581.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16a2ApuJ77sHDeoNbqjRW0VjOY6PlUrcY
"""

#Run the below commands to install tabula and pygwalker
!pip install tabula-py
!pip install pygwalker -q

#importing important libraries for the project

import pandas as pd # Cleaning, Transformation, Analysis, Visualization of data
import csv # Handles SKYWARDS_DATA_CW3.csv file
import matplotlib.pyplot as plt # Creating and customizing plots
import seaborn as sns # Based on matplotlib, used to draw graphics
import pygwalker as pyg # Visualizing customized graphs
import statsmodels.api as smf #  estimation of various statistical models/tests
import numpy as np # arrays, matrices, and  mathematical operations
from sklearn.preprocessing import LabelEncoder # To encode the text vaues into numeric form
from sklearn import preprocessing # preprocessing data before feeding it into machine learning algorithms
from sklearn.model_selection import train_test_split #splits a dataset into training and testing sets
from sklearn.pipeline import Pipeline # chaining together multiple preprocessing/modeling steps into object
from sklearn.compose import ColumnTransformer

# To apply preprocessing techniques to dataset with heterogeneous data types
from sklearn.preprocessing import StandardScaler, OneHotEncoder # prepares data for modeling
from sklearn.tree import DecisionTreeClassifier # builds a decision tree model with training data
from sklearn.ensemble import RandomForestClassifier

#forest of decision trees (each tree is trained on a random subset of the training data)
from sklearn.model_selection import train_test_split, cross_val_score

#evaluates the model's performance by splitting the data into multiple subsets
from sklearn.tree import DecisionTreeRegressor #Root square mean error for Decsion Tree
from sklearn import metrics # evaluation metrics for assessing the performance of models
from sklearn.ensemble import RandomForestRegressor #Root square mean error for Random Forest

#Critical Evaluation of models
# computes accuracy, recall_score, f1_score,roc_auc_score of a classification model:
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
#To compare models
from sklearn.metrics import confusion_matrix

"""# **1. ETL**

# **1.1. Extract Data**
"""

# Specify the path to your Excel file in CSV format
# While working in Googlecollab, I will upload the CSV file and use the following command
excel_csv_file_path = 'SKYWARDS_DATA_CW3.csv'

# Read the CSV-formatted Excel file into a pandas DataFrame
skywards_df = pd.read_csv(excel_csv_file_path,encoding='latin-1')
skywards_df
skywards_df.info()

skywards_df.describe()

"""**Analyze Extracted Data**"""

skywards_df.hist(bins=50, figsize=(18,16));

skywards_df.head()

"""We can see that Easy of Booking is increasing according to the age of customers.

Further EDA may yield additional information such as correlation coefficients...

# **1.2. Transform**

**Clean and Prepare Data for Analysis**

**1.2.1. Handling Missing Values**

Identify if there are any missing values in the data frame
"""

skywards_df.isna().sum()

# we need to make sure there are no missing values in our data

a = skywards_df.isna().value_counts()
skywards_df1 = pd.DataFrame(a)
skywards_df1

"""We can see the Skywards attribute contains some null values which impacts the Arrival Delay in Minutes.
This can be fixed as below:
"""

# Data cleaning and preparation

median = skywards_df['Arrival Delay in Minutes'].median()
skywards_df["Arrival Delay in Minutes"].fillna(median, inplace=True)

a = skywards_df.isna().value_counts()
df1 = pd.DataFrame(a)
df1

"""We can see that there are no null / missing values now.

**1.2.2. Duplicate Rows**

Firstly, the duplicated rows have been identified. Afterwards, different methods have been used to drop the duplicate occurances.
"""

# Duplicate rows in data frame
duplicate_rows = skywards_df[skywards_df.duplicated()]

# Display the duplicate rows
print("Duplicate rows:")
print(duplicate_rows)

# drop duplicates and keep the first occurance only (default behavior)
skywards_df_deduplicated =  skywards_df.drop_duplicates()

# drop duplicates and keep the last occurance
skywards_df_deduplicated_last = skywards_df.drop_duplicates(keep='last')

# drop duplicates based on specific columns
columns_to_check = ['id', 'Age']
skywards_df_deduplicated_custom = skywards_df.drop_duplicates(subset=columns_to_check)

#print the shape of the original and deduplicated dataframes
print("Original dataframe shape:", skywards_df.shape)
print("dedupicated dataframe shape (first occurence):", skywards_df_deduplicated.shape)
print("dedupicated dataframe shape (last occurence):", skywards_df_deduplicated_last.shape)
print("dedupicated dataframe shape (custom subset):", skywards_df_deduplicated_custom.shape)

"""**1.2.3. Remove outliers**

The stats of the last skywards dataframe has been checked by using the describe() function.
"""

#describe stats
skywards_df_deduplicated.describe()

# Visualize data using boxplot function
def plot_boxplot(df, ft):
   df.boxplot(column=[ft])
   plt.grid(False)
   plt.show()
plot_boxplot(skywards_df_deduplicated, 'Flight Distance')

plot_boxplot(skywards_df_deduplicated, 'Departure Delay in Minutes')

"""**Function to Remove Outliers**"""

# remove outliers
def outliers(df, ft):
    Q1 = df[ft].quantile(0.25)
    Q3 = df[ft].quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    ls = df.index[ (df[ft] < lower_bound) | (df[ft] > upper_bound)]
    return ls

# create an empty list to store output indices from multiple columns
index_list = []
for feature in ['Flight Distance', 'Departure Delay in Minutes']:
    index_list.extend(outliers(skywards_df_deduplicated, feature))

index_list

# define a function called "remove" to clear the outliers from data frames
def remove(df, ls):
    ls = sorted(set(ls))
    df = df.drop(ls)
    return df

"""

```
# This is formatted as code
```

The dataframe shape has changed after removing the outliers as below:"""

df_cleaned =  remove(skywards_df_deduplicated, index_list)
df_cleaned.shape

plot_boxplot(df_cleaned, 'Flight Distance')

plot_boxplot(df_cleaned, 'Departure Delay in Minutes')

"""# **1.3. Load**"""

# Data frame after cleaning anomalies and ambiguities
skywards_df_deduplicated

"""# **2. Exploratory Data Analysis (EDA)**"""

#  The percentage of females who are satisfied with the Skywards
female_satisfied_percentage = (skywards_df_deduplicated[skywards_df_deduplicated['Gender'] == 'Female']['Satisfied'] == 'Y').mean() * 100
print("Female satisfied percentage:", female_satisfied_percentage)

#  The percentage of males who are satisfied with the Skywards
male_satisfied_percentage = (skywards_df_deduplicated[skywards_df_deduplicated['Gender'] == 'Male']['Satisfied'] == 'Y').mean() * 100
print("Male satisfied percentage:", male_satisfied_percentage)

#  The percentage of passengers who are satisfied with the Skywards
satisfied_percentage = (skywards_df_deduplicated['Satisfied'] == 'Y').mean() * 100
print("Total Satisfied percentage of customers:", satisfied_percentage)

#  The average of passengers who are satisfied with the Skywards
satisfied_avg = (skywards_df_deduplicated['Satisfied'] == 'Y').mean()
print("Total Satisfied avg of customers:", satisfied_avg)

#  The average Departure/Arrival time convenient according to flight distance
average_dep_arriv_time = skywards_df_deduplicated['Departure/Arrival time convenient'].mean()
print("Average departure arrival time convenient:", average_dep_arriv_time)

#  The average Departure Delay in Minutes for all flights
average_departure_delay = skywards_df_deduplicated['Departure Delay in Minutes'].mean()
print("Average departure delay in minute:", average_departure_delay)

#  The average arrival Delay in Minutes for all flights
average_arrival_delay = skywards_df_deduplicated['Arrival Delay in Minutes'].mean()
print("Average arrival delay in minute:", average_arrival_delay)

# The percentage of safisfied customers in Europe Continent
percentage_satisfied_customers_in_europe = (skywards_df_deduplicated[skywards_df_deduplicated['Continent'] == 'Europe']['Satisfied'] == 'Y').mean() * 100
print("Percentage of satisfied customers in Europe:", percentage_satisfied_customers_in_europe)

# The average asisfied customers in Africa Continent
percentage_satisfied_customers_in_africa = (skywards_df_deduplicated[skywards_df_deduplicated['Continent'] == 'Africa']['Satisfied'] == 'Y').mean() * 100
print("Percentage of satisfied customers in Africa:", percentage_satisfied_customers_in_africa)


# The average asisfied customers in Asia Continent
percentage_satisfied_customers_in_asia = (skywards_df_deduplicated[skywards_df_deduplicated['Continent'] == 'Asia']['Satisfied'] == 'Y').mean() * 100
print("Percentage of satisfied customers in Asia:", percentage_satisfied_customers_in_asia)

# The average asisfied customers in South America Continent
percentage_satisfied_customers_in_south_america = (skywards_df_deduplicated[skywards_df_deduplicated['Continent'] == 'South America']['Satisfied'] == 'Y').mean() * 100
print("Percentage of satisfied customers in South America:", percentage_satisfied_customers_in_south_america)

# The percentage of safistied customers in North America Continent
percentage_satisfied_customers_in_north_america = (skywards_df_deduplicated[skywards_df_deduplicated['Continent'] == 'North America']['Satisfied'] == 'Y').mean() * 100
print("Percentage of satisfied customers in North America:", percentage_satisfied_customers_in_north_america)

"""# **3. Visualization**"""

#create visuals
# Overall Satisfied Customer's Percentage
#Plot 1
labels = ['Satisfied', 'Not Satisfied']
sizes = [satisfied_percentage, 100 - satisfied_percentage]
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.title('Percentage of overall satisfied customers')
plt.show()

#create visuals
# average arrival delay
#Plot 2
labels = ['Average Arrival delay', 'Anamalous']
sizes = [average_arrival_delay, 100 - average_arrival_delay]
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.title('Average arrival delay in Flights')
plt.show()

percentage_satisfiedCustomers_in_diff_continent = [satisfied_percentage, percentage_satisfied_customers_in_europe,
                                                   percentage_satisfied_customers_in_africa,
                                                   percentage_satisfied_customers_in_asia,
                                                   percentage_satisfied_customers_in_south_america,
                                                   percentage_satisfied_customers_in_north_america]
categories = ['all','Europe', 'Africa', 'Asia', 'N-America', 'S-America']
plt.bar(categories, percentage_satisfiedCustomers_in_diff_continent)
plt.ylabel(' Satisfaction Percentage')
plt.title('Satisfaction Rate Continent wise')
plt.show()

# This gives us an idea of the geographical density of the Skywards data

skywards_df.plot(kind='scatter', x='Satisfied', y='Age', alpha=0.1);

skywards_df.plot(kind='scatter', x='Satisfied', y='Flight Distance', alpha=0.1);

skywards_df.plot(kind="scatter", x="Ease of Online booking", y="Age", alpha=0.9,
    s=skywards_df["Flight Distance"]/100, label="Flight Distance", figsize=(10,7),
    c="Departure/Arrival time convenient", cmap=plt.get_cmap("jet"), colorbar=True,
)
plt.legend();

print("\nSkywards data frame")
pyg.walk(skywards_df_deduplicated)

"""**Pivot Table**"""

pivot_table = skywards_df_deduplicated.pivot_table(index='Ref', columns='Gender', values='Satisfied', aggfunc='mean')
print(pivot_table)

"""# **4. Select and Train Models**

**Conversion of Non-numeric Data**
"""

#The following columns contain non-numeric data

print("Satisfied Data:\n",skywards_df_deduplicated['Satisfied'].value_counts())
print("Gender Data:\n",skywards_df_deduplicated['Gender'].value_counts())
print("Age Band Data:\n",skywards_df_deduplicated['Age Band'].value_counts())
print("Type of Travel\n",skywards_df_deduplicated['Type of Travel'].value_counts())
print("Class Data:\n",skywards_df_deduplicated['Class'].value_counts())
print("Destination Data:\n",skywards_df_deduplicated['Destination'].value_counts())
print("Continent Data:\n",skywards_df_deduplicated['Continent'].value_counts())

"""We will now convert these attributes to numerical values.

---


"""

columns_to_encode = ['Satisfied', 'Gender', 'Type of Travel','Age Band','Class', 'Destination', 'Continent']
# Encode multiple columns at once
le = LabelEncoder()
skywards_df_deduplicated[columns_to_encode] = skywards_df_deduplicated[columns_to_encode].apply(lambda col: le.fit_transform(col))

# Check the encoded values
for column in columns_to_encode:
    print("Encoded values:",column)
    print(skywards_df_deduplicated[column].value_counts())

"""**Feature Scaling Example**

Currently, out input data is at different scale - Flight Distance is in the thousands while Travel Type, class, etc are just one digit..

Some ML models work best with data in the 0-1 range so we use a scaling technique that does this... min-max scaling or standardization.

Our models below can use the data at orginal scale, but there is an example of scaled data below for illustration.

We split our data into features and labels as we only scale the feature data...
"""

X= skywards_df_deduplicated.drop('Flight Distance', axis=1) # features
y = skywards_df_deduplicated['Satisfied'] # label

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

print(X_train.shape)
print(X_test.shape)

X_train.head()

cols = X_train.columns

min_max_scaler = preprocessing.MinMaxScaler()
np_scaled = min_max_scaler.fit_transform(X_train)
df_normalized = pd.DataFrame(np_scaled, columns = cols)
df_normalized.head()

"""This example above shows the scaling of the data, but we only use this for specific types of models.  Take note of the models below - notice which inputs are being used when fitting features to labels...

# **4.1. Decison Tree**
"""

X= skywards_df_deduplicated[['Gender','Age','Type of Travel','Class',
                             'Departure/Arrival time convenient',
                             'Ease of Online booking','Online boarding']] # features
y = skywards_df_deduplicated['Satisfied'] # Target Variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Decision Tree model
dt_classifier = DecisionTreeClassifier(random_state=42)
dt_classifier.fit(X_train, y_train)

# Predictions
dt_pred = dt_classifier.predict(X_test)

# Evaluate the model
dt_accuracy = accuracy_score(y_test, dt_pred)
print("Decision Tree Accuracy:", dt_accuracy)

"""**Passing data to Decision Tree model**"""

#user input for a new customer
new_customer = [[0,55,2,1,1,1,1]]
approval_perdiction = dt_classifier.predict(new_customer)

if approval_perdiction[0] == 1:
  print("The customer is Satisfied.")
else:
  print("The customer is not Satisfied.")

#user input for a new customer
new_customer = [[0,1,2,1,1,1,1]]
approval_perdiction1 = dt_classifier.predict(new_customer)

if approval_perdiction1[0] == 1:
  print("The customer is Satisfied.")
else:
  print("The customer is not Satisfied.")

"""# **4.2. Random** **Forest**"""

X= skywards_df_deduplicated[['Gender','Age','Type of Travel','Class',
                             'Departure/Arrival time convenient',
                             'Ease of Online booking','Online boarding']] # features
y = skywards_df_deduplicated['Satisfied'] # Target Variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Random Forest model
rf_classifier = RandomForestClassifier(random_state=42)
rf_classifier.fit(X_train, y_train)

# Predictions
rf_pred = rf_classifier.predict(X_test)

# Evaluate the model
rf_accuracy = accuracy_score(y_test, rf_pred)
print("Random Forest Accuracy:", rf_accuracy)

"""**Passing Data to Random Forest Model**"""

correct_predictions_rf = (y_test == rf_pred).sum()
incorrect_predictions_rf = (y_test != rf_pred).sum()

#user input for a new customer
new_customer = [[0,55,2,1,1,1,1]]
approval_perdiction = rf_classifier.predict(new_customer)

if approval_perdiction[0] == 1:
  print("The customer is Satisfied.")
else:
  print("The customer is not Satisfied.")

"""# **5. Evaluate Both Models**"""

# Decision Tree Model
dt_scores = cross_val_score(dt_classifier, X_train, y_train, cv=5)  # 5-fold cross-validation
dt_accuracy = dt_scores.mean()

# Random Forest Model
rf_scores = cross_val_score(rf_classifier, X_train, y_train, cv=5)  # 5-fold cross-validation
rf_accuracy = rf_scores.mean()

print("Decision Tree Accuracy (Cross-Validation):", dt_accuracy)
print("Random Forest Accuracy (Cross-Validation):", rf_accuracy)

"""The above code provides an unbiased estimate of the models' accuracy by evaluating them on different subsets of the training data.Since the accuracy of both models is slightly different by 0.004. We will consider some additional factors to ensure which model to choose.

**Compare other metrics for DT and RF Models**
"""

# Compare other metrics
dt_precision = precision_score(y_test, dt_pred)
rf_precision = precision_score(y_test, rf_pred)

dt_recall = recall_score(y_test, dt_pred)
rf_recall = recall_score(y_test, rf_pred)

dt_f1 = f1_score(y_test, dt_pred)
rf_f1 = f1_score(y_test, rf_pred)

print("Decision Tree Accuracy:", dt_accuracy)
print("Random Forest Accuracy:", rf_accuracy)

print("\nDecision Tree Precision:", dt_precision)
print("Random Forest Precision:", rf_precision)

print("\nDecision Tree Recall:", dt_recall)
print("Random Forest Recall:", rf_recall)

print("\nDecision Tree F1 Score:", dt_f1)
print("Random Forest F1 Score:", rf_f1)

"""**Root Mean Square Error**"""

tree_reg = DecisionTreeRegressor()
tree_reg.fit(X_train, y_train)
y_pred_tree_reg = tree_reg.predict(X_test)
tree_reg_MSE= metrics.mean_squared_error(y_test, y_pred_tree_reg)
tree_reg_RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred_tree_reg))
print('Decision Tree Mean Squared Error:', tree_reg_MSE)
print('Decision Root Mean Squared Error:', tree_reg_RMSE)

forest_reg = RandomForestRegressor()
forest_reg.fit(X_train, y_train)

y_pred_forest = forest_reg.predict(X_test)
forest_MSE= metrics.mean_squared_error(y_test, y_pred_forest)
forest_RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred_forest))
print('Random Forest Regression Mean Squared Error:', forest_MSE)
print('Random Forest Regression Root Mean Squared Error:', forest_RMSE)

"""**RMSE Comparison**"""

data = {
    'Decision Tree': [tree_reg_RMSE],
    'Random Forest': [forest_RMSE]}


# Create DataFrame
df_comp = pd.DataFrame(data)
df_comp = df_comp.rename(index={0 : 'Root Mean Squared Error'})

# Print the output.
df_comp

"""**MSE Comparison**"""

data = {
    'Decision Tree': [tree_reg_MSE],
    'Random Forest': [forest_MSE]}


# Create DataFrame
df_comp = pd.DataFrame(data)
df_comp = df_comp.rename(index={0 : 'Mean Squared Error'})

# Print the output.
df_comp

"""**Critical Evlautaion of Models**

a. Including an explanation of your chosen loss function
"""

# Predictions on test data
dt_pred = dt_classifier.predict(X_test)
rf_pred = rf_classifier.predict(X_test)

# Evaluation metrics
dt_accuracy = accuracy_score(y_test, dt_pred)
rf_accuracy = accuracy_score(y_test, rf_pred)

dt_precision = precision_score(y_test, dt_pred)
rf_precision = precision_score(y_test, rf_pred)

dt_recall = recall_score(y_test, dt_pred)
rf_recall = recall_score(y_test, rf_pred)

dt_f1_score = f1_score(y_test, dt_pred)
rf_f1_score = f1_score(y_test, rf_pred)

dt_roc_auc = roc_auc_score(y_test, dt_pred)
rf_roc_auc = roc_auc_score(y_test, rf_pred)

# Chosen loss function (e.g., accuracy)
chosen_loss_function = "Accuracy"

# Comparison of models
print("Decision Tree Model Evaluation:")
print("Accuracy:", dt_accuracy)
print("Precision:", dt_precision)
print("Recall:", dt_recall)
print("F1 Score:", dt_f1_score)
print("ROC AUC Score:", dt_roc_auc)

print("\nRandom Forest Model Evaluation:")
print("Accuracy:", rf_accuracy)
print("Precision:", rf_precision)
print("Recall:", rf_recall)
print("F1 Score:", rf_f1_score)
print("ROC AUC Score:", rf_roc_auc)

# Generalization assessment
print("\nGeneralization Assessment:")
print("Decision Tree Model Generalization:", "Good" if dt_accuracy >= 0.8 else "Poor")
print("Random Forest Model Generalization:", "Good" if rf_accuracy >= 0.8 else "Poor")

"""**Comparison Table**"""

# Assuming dt_pred and rf_pred are the predictions for DT and RF

# Calculate precision, recall, and F1-score for Decision Tree model
dt_precision = precision_score(y_test, dt_pred)
dt_recall = recall_score(y_test, dt_pred)
dt_f1_score = f1_score(y_test, dt_pred)
dt_roc_auc = roc_auc_score(y_test, dt_pred)

# Calculate precision, recall, and F1-score for Random Forest model
rf_precision = precision_score(y_test, rf_pred)
rf_recall = recall_score(y_test, rf_pred)
rf_f1_score = f1_score(y_test, rf_pred)
rf_roc_auc = roc_auc_score(y_test, rf_pred)

# Create a DataFrame to display the results
metrics_df = pd.DataFrame({
    'Metric': ['Precision', 'Recall', 'F1-score', 'ROC-AUC'],
    'Decision Tree': [dt_precision, dt_recall, dt_f1_score, dt_roc_auc],
    'Random Forest': [rf_precision, rf_recall, rf_f1_score, rf_roc_auc]
})

print(metrics_df)

"""**Comparing two Models**

Accuracy metric, the number of correct predictions, and the number of
incorrect prediction results
"""

# Assuming dt_pred and rf_pred are the predictions for Decision Tree and Random Forest models respectively

# Calculate accuracy scores
dt_accuracy = accuracy_score(y_test, dt_pred)
rf_accuracy = accuracy_score(y_test, rf_pred)

# Calculate confusion matrices
dt_conf_matrix = confusion_matrix(y_test, dt_pred)
rf_conf_matrix = confusion_matrix(y_test, rf_pred)

# Extract correct and incorrect predictions from confusion matrices
dt_correct_pred = dt_conf_matrix[0, 0] + dt_conf_matrix[1, 1]
dt_incorrect_pred = dt_conf_matrix[0, 1] + dt_conf_matrix[1, 0]

rf_correct_pred = rf_conf_matrix[0, 0] + rf_conf_matrix[1, 1]
rf_incorrect_pred = rf_conf_matrix[0, 1] + rf_conf_matrix[1, 0]

# Create a DataFrame for comparison
data = {
    'Model': ['Decision Tree', 'Random Forest'],
    'Accuracy': [dt_accuracy, rf_accuracy],
    'Correct Predictions': [dt_correct_pred, rf_correct_pred],
    'Incorrect Predictions': [dt_incorrect_pred, rf_incorrect_pred]
}

comparison_table = pd.DataFrame(data)
print(comparison_table)

"""# **6. Visualization of Results**

**6.1. Correlational Matrix**
"""

# Compute the correlation matrix
correlation_matrix = skywards_df_deduplicated.corr()

# Display the correlation matrix
print("Correlation Matrix:")
print(correlation_matrix)

"""**6.2. Heat map**"""

#heat map with correlation matrix
plt.figure(figsize=(16,14))
corr_matrix= skywards_df_deduplicated.corr()
# create a heatmap with seaborn
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".1f")

plt.title('Correlation Heatmap of Skywards DataFrame')
plt.show()

"""**6.3. Confusion Matrix**"""

# Assuming y_test and rf_pred are your true labels and predicted labels, respectively
cm_rf = confusion_matrix(y_test, rf_pred)

# Plot confusion matrix using seaborn heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={"size": 16})
plt.title('Random Forest Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

#for decision tree

# Assuming y_test and df_pred are your true labels and predicted labels, respectively
cm_dt = confusion_matrix(y_test, dt_pred)

# Plot confusion matrix using seaborn heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm_dt, annot=True, fmt='d', cmap='Blues', cbar=False, annot_kws={"size": 16})
plt.title('Decision tree Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()